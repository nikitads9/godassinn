version: "3.8"

networks:
  app_net:
    driver: bridge
  elk:
    driver: bridge

volumes:
  postgres-volume:
  certificates-volume:
  prometheus-volume:
  jaeger-volume:
  elasticsearch:

services:
  # NGINX load balancer and proxy
  nginx-entrypoint:
    image: nginx
    hostname: nginx-entrypoint
    container_name: nginx-entrypoint
    restart: unless-stopped
    environment:
      TZ: "Europe/Moscow"
    volumes:
      - certificates-volume:/etc/ssl/certs
      - ./booking-schedule/backend/deploy/nginx/nginx.conf:/etc/nginx/nginx.conf
    ports:
      - 80:80
      - 443:443
    networks:
      - app_net
    depends_on:
      - booking
      - auth
  
  # Postgresql database
  db:
    container_name: booking-storage
    image: postgres:16-alpine3.19
    environment:
      - "POSTGRES_DB=${DB_NAME}"
      - "POSTGRES_USER=${DB_USER}"
      - "POSTGRES_PASSWORD=${DB_PASSWORD}"
      - "PGDATA=${PGDATA}"
    volumes: 
      - postgres-volume:/var/lib/postgresql/data
    #  - ./booking-schedule/backend/deploy/database/init.sql:/docker-entrypoint-initdb.d/init.sql 
    ports:
      - "${DB_PORT}:${DB_PORT}"
    expose:
    - "${DB_PORT}" 
    command: -p ${DB_PORT}
    networks:
      - app_net

  # Booking service
  booking:
    container_name: booking
    build:
      context: .
      dockerfile: ./booking-schedule/backend/deploy/bookings/Dockerfile
    image: nikitads9/booking-schedule:booking
    volumes:
      - certificates-volume:/etc/ssl/certs
    ports:
      - "${BOOKINGS_PORT}:${BOOKINGS_PORT}"
    depends_on:
      - db
      - jaeger
    networks:
      - app_net
    deploy:
      resources:
        limits:
          memory: 200m
          cpus: "0.50"
    logging:
      driver: gelf
      options:
        gelf-address: 'udp://:12201'
        tag: 'booking'

  # Service for signing in and up for users
  auth:
    container_name: auth
    build:
      context: .
      dockerfile: ./booking-schedule/backend/deploy/auth/Dockerfile
    image: nikitads9/booking-schedule:auth
    volumes:
      - certificates-volume:/etc/ssl/certs
    ports:
      - "${AUTH_PORT}:${AUTH_PORT}"
    depends_on:
      - db
      - jaeger
    networks:
      - app_net
    deploy:
      resources:
        limits:
          memory: 200m
          cpus: "0.70"
    logging:
      driver: gelf
      options:
        gelf-address: 'udp://:12201'
        tag: 'auth'

  # Goose migrations manager
  migrator:
    container_name: migrator
    build: $MIGRATION_DIR
    restart: on-failure
    image: nikitads9/booking-schedule:migrator
    environment:
      - "GOOSE_DRIVER=postgres"
      - "GOOSE_DBSTRING=host=${DB_HOST} port=${DB_PORT} dbname=${DB_NAME} user=${DB_USER} password=${DB_PASSWORD} sslmode=${DB_SSL}"
      - "MIGRATION_DIR=${MIGRATION_DIR}"
    depends_on:
      - db
    networks:
      - app_net

  # Periodic task agent
  scheduler:
    container_name: scheduler
    build:
      context: .
      dockerfile: ./booking-schedule/backend/deploy/scheduler/Dockerfile
    image: nikitads9/booking-schedule:scheduler
    restart: unless-stopped
    environment:
      - "DB_NAME=${DB_NAME}"
      - "DB_USERNAME=${DB_USER}"
      - "DB_PASSWORD=${DB_PASSWORD}"
      - "DB_HOST=${DB_HOST}"
    depends_on:
      - db
      - queue
    networks:
      - app_net
    deploy:
      resources:
        limits:
          memory: 200m
          cpus: "0.30"
    logging:
      driver: gelf
      options:
        gelf-address: 'udp://:12201'
        tag: 'scheduler'

  # Template for sender service
  sender:
    container_name: sender
    build:
      context: .
      dockerfile: ./booking-schedule/backend/deploy/sender/Dockerfile
    image: nikitads9/booking-schedule:sender
    restart: unless-stopped
    depends_on:
      - queue
    networks:
      - app_net
    deploy:
      resources:
        limits:
          memory: 200m
          cpus: "0.30"
    logging:
      driver: gelf
      options:
        gelf-address: 'udp://:12201'
        tag: 'sender'

  # RabbitMQ AMQP queue
  queue:
    container_name: queue
    image: rabbitmq:3.13.0-management-alpine
    environment:
      RABBITMQ_DEFAULT_PASS: ${AMQP_PASS}
      RABBITMQ_DEFAULT_USER: ${AMQP_USER}
      RABBITMQ_DEFAULT_VHOST: ${AMQP_VHOST}
    volumes:
      - ~/.docker-conf/rabbitmq/data/:/var/lib/rabbitmq/
      - ~/.docker-conf/rabbitmq/log/:/var/log/rabbitmq
    ports:
      - "${AMQP_PORT}:${AMQP_PORT}"
      - "15672"
    expose:
      - "${AMQP_PORT}"
    networks:
      - app_net

  # Jaeger tracing and monitoring
  jaeger:
    container_name: jaeger
    image: jaegertracing/all-in-one:latest
    command:
      - "--query.base-path=/jaeger/ui"
      - "--prometheus.server-url=${PROMETHEUS_ADDR}"
      - "--prometheus.query.support-spanmetrics-connector=true"
      - "--prometheus.query.normalize-calls=true"
      - "--prometheus.query.normalize-duration=true"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - METRICS_STORAGE_TYPE=prometheus
      - PROMETHEUS_SERVER_URL=${PROMETHEUS_ADDR}
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_TAGS_AS_FIELDS_ALL=true
      - ES_SERVER_URLS=http://elasticsearch:9200
      - ES_USERNAME=elastic
      - ES_PASSWORD=${ELASTIC_PASSWORD}
    ports:
      #- "5775:5775/udp" # agent accept zipkin.thrift over compact thrift protocol (deprecated, used by legacy clients only)
      #- "6831:6831/udp" # agent accept jaeger.thrift over compact thrift protocol
      #- "6832:6832/udp" # agent accept jaeger.thrift over binary thrift protocol
      #- "5778:5778" # agent serve configs
      #- "16686:16686" # query serve frontend (Jaeger UI)
      #- "14268:14268" # collector accept jaeger.thrift directly from clients
      #- "14250:14250" # collector accept model.proto
      #- "9411:9411" # collector Zipkin compatible endpoint (optional)
      - '14269:14269'
      - '4317:4317' # OTLP collector grpc
      - '4318:4318' # OTLP collector http
      - '16686:16686'
      - '16685:16685'
    expose:
      - '4317'
      - '14269'
    networks:
      - app_net
      - elk

  # Prometheus monitoring and TSDB
  prometheus:
    container_name: prometheus
    image: prom/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus' #Where Prometheus writes its database. Defaults to data/.
      - '--storage.tsdb.retention.time=1d' #When to remove old data. Defaults to 15d. Overrides storage.tsdb.retention if this flag is set to anything other than default.
      - '--storage.tsdb.retention.size=1GB'
      - '--enable-feature=otlp-write-receiver'
    volumes:
      - ./booking-schedule/backend/deploy/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-volume:/prometheus
    ports:
      - '9090:9090'
    networks:
      - app_net

  # OpenTelemetry Collector
  otelcol:
    container_name: otelcol
    image: otel/opentelemetry-collector-contrib:latest
    deploy:
      resources:
        limits:
          memory: 200M
    restart: unless-stopped
    command: [ "--config=/etc/otelcol-config.yml" ]
    environment:
      - DB_MONITOR_USER=${DB_MONITOR_USER}
      - DB_MONITOR_PASSWORD=${DB_MONITOR_PASSWORD}
      - DB_NAME=${DB_NAME}
    volumes:
      - ./booking-schedule/backend/deploy/otelcollector/otelcol-config.yml:/etc/otelcol-config.yml
    expose:
      - '4318'
    ports:
      - '14318:4318'
    depends_on:
      - jaeger
    networks:
      - app_net

  logstash:
    container_name: logstash
    image: logstash:${ELASTIC_VERSION}
    #build:
    #  context: deploy/logstash/
    #  args:
    #    ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./booking-schedule/backend/deploy/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./booking-schedule/backend/deploy/logstash/pipeline:/usr/share/logstash/pipeline:ro,Z
    ports:
      - 12201:12201/udp
      - 5044:5044
      - 50000:50000/tcp
      - 50000:50000/udp
      - 9600:9600
    environment:
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 800m
          cpus: "0.8"

  elasticsearch:
    container_name: elasticsearch
    image: elasticsearch:${ELASTIC_VERSION}
    #build:
    #  context: deploy/elasticsearch/
    #  args:
    #    ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./booking-schedule/backend/deploy//elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,Z
      - elasticsearch:/usr/share/elasticsearch/data:Z
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      node.name: elasticsearch
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      # Bootstrap password.
      # Used to initialize the keystore during the initial startup of
      # Elasticsearch. Ignored on subsequent runs.
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    networks:
      - elk
    restart: unless-stopped

  kibana:
    container_name: kibana
    image: kibana:${ELASTIC_VERSION}
    #build:
    #  context: deploy/kibana/
    #  args:
    #    ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./booking-schedule/backend/deploy//kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
    ports:
      - 5601:5601
    environment:
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch
    restart: unless-stopped

      # The 'setup' service runs a one-off script which initializes users inside
  # Elasticsearch — such as 'logstash_internal' and 'kibana_system' — with the
  # values of the passwords defined in the '.env' file. It also creates the
  # roles required by some of these users.
  #
  # This task only needs to be performed once, during the *initial* startup of
  # the stack. Any subsequent run will reset the passwords of existing users to
  # the values defined inside the '.env' file, and the built-in roles to their
  # default permissions.
  #
  # By default, it is excluded from the services started by 'docker compose up'
  # due to the non-default profile it belongs to. To run it, either provide the
  # '--profile=setup' CLI flag to Compose commands, or "up" the service by name
  # such as 'docker compose up setup'.
  elksetup:
    container_name: elksetup
    profiles:
      - setup
    build:
      context: ./booking-schedule/backend/deploy/elksetup/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    init: true
    volumes:
      - ./booking-schedule/backend/deploy/elksetup/entrypoint.sh:/entrypoint.sh:ro,Z
      - ./booking-schedule/backend/deploy/elksetup/lib.sh:/lib.sh:ro,Z
      - ./booking-schedule/backend/deploy/elksetup/roles:/roles:ro,Z
    environment:
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
      FILEBEAT_INTERNAL_PASSWORD: ${FILEBEAT_INTERNAL_PASSWORD:-}
      BEATS_SYSTEM_PASSWORD: ${BEATS_SYSTEM_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch

